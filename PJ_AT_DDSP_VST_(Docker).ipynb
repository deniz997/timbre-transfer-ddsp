{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# @title Dependencies installation\n",
        "\n",
        "# @markdown Run this code just once, after setting up the docker.\n",
        "\n",
        "from time import time\n",
        "start = time()\n",
        "\n",
        "!wget --no-check-certificate 'https://docs.google.com/uc?export=download&id=1pt0jsdnLrvDya7QMyQvh_qmEX2lifalz' -O requirements.txt\n",
        "#!pip uninstall -y keras tensorflow tensorflow-probability absl-py astunparse flatbuffers gast google-pasta grpcio h5py keras keras-preprocessing libclang numpy opt-einsum protobuf setuptools six tensorboard tensorflow-io-gcs-filesystem termcolor tf-estimator-nightly typing-extensions wrapt\n",
        "!pip install -r requirements.txt --no-deps\n",
        "\n",
        "!pip install pyocclient\n",
        "\n",
        "print(f\"Installation took {int(time()-start)}s.\")\n",
        "print(\"Please click on 'Restart Session' button above.\")"
      ],
      "metadata": {
        "id": "qFfGsmJ-MiLR",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python --version"
      ],
      "metadata": {
        "id": "LAdssp0Tsk_t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Information\n",
        "# @markdown ##About\n",
        "\n",
        "#@markdown With this colab, it is possible to train a single or multiple VST3-Models. </br>\n",
        "#@markdown They can be used to synth or tone-shift input audio to an instrument that can be trained here </br>\n",
        "\n",
        "#@markdown This colab was modified to be usable using the ressources of a local machine,\n",
        "#@markdown that runs a colab-docker image. </br>\n",
        "#@markdown For further information, see here:  [research.google.com](https://research.google.com/colaboratory/local-runtimes.html)\n",
        "\n",
        "\n",
        "# @markdown ##Content\n",
        "\n",
        "#@markdown - With the first cell it is possible to train one model\n",
        "#@markdown - The second one allows the training of multiple models\n",
        "#@markdown   - The run of the first cell (with *Run_Training* set to *False*) is still necessary\n",
        "#@markdown - As for the visualization of the loss during the training, the last cell can be called"
      ],
      "metadata": {
        "cellView": "form",
        "id": "clb-jQEpcdK6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VxPuPR0j5Gs7",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "# ------------------------------------------------------------------------------\n",
        "#     Copyright 2022 Google LLC. All Rights Reserved.\n",
        "#\n",
        "#     Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "#     you may not use this file except in compliance with the License.\n",
        "#     You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "#     Unless required by applicable law or agreed to in writing, software\n",
        "#     distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "#     WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "#     See the License for the specific language governing permissions and\n",
        "#     limitations under the License.\n",
        "# ------------------------------------------------------------------------------\n",
        "\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# User Interface\n",
        "# ------------------------------------------------------------------------------\n",
        "\n",
        "# @title DDSP-VST Model Training\n",
        "#@markdown #  Train your own DDSP-VST Model (docker version)\n",
        "#@markdown üéªüé∫üé∏üéµ [g.co/magenta/train-ddsp-vst](g.co/magenta/train-ddsp-vst)\n",
        "\n",
        "#@markdown <br/>\n",
        "\n",
        "#@markdown ## Instructions\n",
        "\n",
        "#@markdown * Create a folder in Google Drive with your training audio (`.wav` or `.mp3`)\n",
        "\n",
        "from keras.dtensor import dtensor_api as dtensor\n",
        "\n",
        "Name = 'mymodel' #@param {type:\"string\"}\n",
        "Name = Name.replace(' ', '_')\n",
        "\n",
        "#@markdown <br/> Link to tubCloud dataset directory/archive with audio files. The link should be public. TODO\n",
        "Dataset_Link = 'https://tubcloud.tu-berlin.de/s/3gmWPiK4xKRjXKd'  #@param {type:\"string\"}\n",
        "\n",
        "#@markdown <br/>\n",
        "#@markdown Use Cloud services for training? Otherwise, loads audio from browser, which is much slower.\n",
        "Cloud_Service = \"TUB-Cloud/Nextcloud\" #@param [\"Google Drive\", \"TUB-Cloud/Nextcloud\", \"None\"]\n",
        "\n",
        "Cloud_File_Name = 'wolves.wav.zip' #@param {type:\"string\"}\n",
        "\n",
        "# Global declerations\n",
        "CLOUD_NONE = 0\n",
        "CLOUD_NEXTCLOUD = 1\n",
        "CLOUD_GDRIVE = 2\n",
        "\n",
        "Run_Training = True #@param {type:\"boolean\"}\n",
        "\n",
        "#@markdown * Set Run_Training to **true**\n",
        "\n",
        "#@markdown * Press the ‚ñ∂Ô∏è button in the upper left!\n",
        "\n",
        "#@markdown * Login to your Google account when asked\n",
        "\n",
        "#@markdown *  Select your folder with the file chooser below when asked\n",
        "\n",
        "#@markdown *  Wait (with this window open) for training to finish and download the model\n",
        "\n",
        "#@markdown *  If something breaks, resume training by refreshing this page, press ‚ñ∂Ô∏è, and choose the same folder\n",
        "\n",
        "\n",
        "\n",
        "#@markdown <br/>\n",
        "\n",
        "#@markdown <br/>\n",
        "\n",
        "#@markdown ## Data\n",
        "#@markdown Custom models can train on as little as 10 minutes of audio (`.wav` or `.mp3`). You can get the best results from \"monophonic\" (only one note at a time) audio from a single recording session (same mic, same reverb). All of your data is private, used locally, and erased as soon as your colab session ends.\n",
        "\n",
        "#@markdown We recommend using Google Drive to load data faster and save your model during training. Just create a folder on your drive with your audio files in it, and select the folder. If you don't use drive, you can still upload audio through the browser (slower) and download the final trained model.\n",
        "\n",
        "\n",
        "#@markdown ## Training\n",
        "#@markdown Training typically takes ~2-3 hours with free Colab, and less than an hour with ColabPro+. Free colab can sometimes disconnects before models finish training, but there are some unofficial [ways around this](https://stackoverflow.com/questions/57113226/how-to-prevent-google-colab-from-disconnecting). If you do get disconnected, don't worry, just press play again and choose the same folder. The training will resume where it left off.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#@markdown ## Export\n",
        "\n",
        "#@markdown After training, the colab should automatically export, zip, and download your model folder. To use, just unzip and drop the full folder in plugin model folder (Mac: `~/Documents/Magenta/DDSP/Models`, which you can also find from inside the plugin).\n",
        "\n",
        "#@markdown If it doesn't automatically download, you can also find it in your training folder (`ddsp-training-{date-time}/{Name}`). Also, you'll likely see a bunch of warnings like `Value in checkpoint could not be found in the restored object`, don't worry that's normal :).\n",
        "\n",
        "\n",
        "#@markdown <br/> <br/>\n",
        "#@markdown ## Advanced Options\n",
        "\n",
        "##@markdown <a href=\"https://colab.research.google.com/github/magenta/ddsp/blob/main/ddsp/colab/demos/Train_VST.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
        "\n",
        "#@markdown <br/>\n",
        "#@markdown  Usually we will produce good results after training between 30k-50k steps, but your results may vary depending on your audio files/instrument. Too few steps will often have the model sound bland/generic, too many steps can often lead to more \"sputtering\" and big volume fluctuations\n",
        "\n",
        "Training_Steps = 50000 #@param {type:\"integer\"}\n",
        "\n",
        "Steps_Per_Save = 1000 #@param {type:\"integer\"}\n",
        "\n",
        "#@markdown <br/>\n",
        "#@markdown Restart the training each time at mulitple of this step (0=no restart).<br/>\n",
        "#@markdown TODO: fix the generated .gin file (incorrect comment on # of taining steps)\n",
        "Threshold = 1000 #@param {type:\"integer\", min:0, max:50000}\n",
        "\n",
        "#@markdown At which training step should the restart using <i>Threshold</i> begin.\n",
        "#@markdown Useful if a previous training got interrupted.\n",
        "Threshold_Start = 0 #@param {type:\"integer\", min:0, max:50000}\n",
        "\n",
        "#@markdown <br/>\n",
        "#@markdown Ignore previous checkpoints in the folder and start a fresh run from step 0\n",
        "\n",
        "Ignore_Previous = False #@param {type:\"boolean\"}\n",
        "\n",
        "#@markdown <br/>\n",
        "#@markdown Disconnect from session after the training is completed. <br/>\n",
        "#@markdown Use it only when <b>Google_Drive</b> is enabled. The model-ZIP will be saved there. TODO REMOVE/REPLACE WITH SHUTDOWN\n",
        "Disconnect_Finished = False #@param {type:\"boolean\"}\n",
        "\n",
        "\n",
        "##@markdown ---\n",
        "##@markdown <sub> This notebook sends anonymous usage data (i.e. training time) to Google Analytics to help improve/debug training. All audio and model information is private, and not sent or stored. For more information, see [Google's privacy policy](https://policies.google.com/privacy). </sub>\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# Imports (not DDSP Dependent)\n",
        "# ------------------------------------------------------------------------------\n",
        "# Supress warnings that obscure output.\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "import datetime\n",
        "import glob\n",
        "import os\n",
        "import shutil\n",
        "import time\n",
        "import IPython\n",
        "import json\n",
        "import subprocess\n",
        "import termcolor\n",
        "\n",
        "from google.colab import drive, runtime\n",
        "import tensorflow as tf\n",
        "\n",
        "from ipyfilechooser import FileChooser\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# Import DDSP\n",
        "# ------------------------------------------------------------------------------\n",
        "from ddsp.colab import colab_utils\n",
        "globals()['colab_utils'] = colab_utils\n",
        "\n",
        "\n",
        "# Global variables\n",
        "export_path = ''\n",
        "\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# Functions\n",
        "# ------------------------------------------------------------------------------\n",
        "def get_data_from_nextcloud(public_share_link, dataset_fn):\n",
        "    import owncloud\n",
        "    bn = os.path.basename(dataset_fn)\n",
        "    bn = bn.lower()\n",
        "    bn = bn.replace(\" \", \"_\")\n",
        "\n",
        "    try:\n",
        "        oc = owncloud.Client.from_public_link(public_share_link)\n",
        "    except:\n",
        "        print(f\"Failed to initialize OC-client for link: {public_share_link}\")\n",
        "        return\n",
        "\n",
        "    try:\n",
        "        if not oc.get_file(dataset_fn, bn):\n",
        "            print(f\"Error retrieving file {dataset_fn}. Client failed gracefully\")\n",
        "        else:\n",
        "            if bn.endswith(\".zip\"):\n",
        "                dir_name = bn[:-4]\n",
        "                !unzip -o $bn -d $dir_name\n",
        "                return dir_name\n",
        "            else:\n",
        "                return bn\n",
        "    except Exception as e:\n",
        "      print(f\"Error occured while loading/unzipping file {dataset_fn}\")\n",
        "      raise e\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def directory_has_files(target_dir):\n",
        "  n_files = len(glob.glob(os.path.join(target_dir, '*')))\n",
        "  return n_files > 0\n",
        "\n",
        "\n",
        "def get_audio_files(cloud_service_type, cloud_link, audio_dir):\n",
        "  audio_paths = []\n",
        "  print(\"Cloud service type\", cloud_service_type)\n",
        "\n",
        "  if cloud_service_type == CLOUD_NEXTCLOUD:\n",
        "    print(cloud_link)\n",
        "    cloud_audio_dir = get_data_from_nextcloud(cloud_link, Cloud_File_Name)\n",
        "    termcolor.cprint(f\"Audio directory: {audio_dir}\", \"green\")\n",
        "\n",
        "    mp3_files = glob.glob(os.path.join(cloud_audio_dir, '*.mp3'))\n",
        "    wav_files = glob.glob(os.path.join(cloud_audio_dir, '*.wav'))\n",
        "    audio_paths = mp3_files + wav_files\n",
        "\n",
        "  elif cloud_service_type == CLOUD_GDRIVE:\n",
        "    print(cloud_link)\n",
        "    raise Exception(\"Not implemented\")\n",
        "  else:\n",
        "    # See if there are already some audio files\n",
        "    mp3_files = glob.glob(os.path.join(audio_dir, '*.mp3'))\n",
        "    wav_files = glob.glob(os.path.join(audio_dir, '*.wav'))\n",
        "    audio_paths = mp3_files + wav_files\n",
        "\n",
        "    if len(audio_paths) > 0:\n",
        "      print(f\"Found {len(audio_paths)} files in {audio_dir}, skipping upload.\")\n",
        "      return\n",
        "\n",
        "    print(f\"No files found in {audio_dir}.\")\n",
        "    audio_paths, _ = colab_utils.upload()\n",
        "\n",
        "  # Copy Audio.\n",
        "  print('Copying audio to colab for training...')\n",
        "  for src in audio_paths:\n",
        "    target = os.path.join(audio_dir,\n",
        "                          os.path.basename(src).replace(' ', '_'))\n",
        "    print('Copying {} to {}'.format(src, target))\n",
        "    shutil.copy(src, target)\n",
        "    # !cp $src $target\n",
        "\n",
        "\n",
        "def prepare_dataset(audio_dir,\n",
        "                    data_dir,\n",
        "                    sample_rate=16000,\n",
        "                    frame_rate=50,\n",
        "                    example_secs=4.0,\n",
        "                    hop_secs=1.0,\n",
        "                    viterbi=True,\n",
        "                    center=True):\n",
        "  if directory_has_files(data_dir):\n",
        "    print(f'Dataset already exists in `{data_dir}`')\n",
        "    return\n",
        "  else:\n",
        "    # Otherwise prepare new dataset locally.\n",
        "    print(f'Preparing new dataset from `{audio_dir}`')\n",
        "\n",
        "    print()\n",
        "    print('Creating dataset...')\n",
        "    print('This usually takes around 2-3 minutes for each minute of audio')\n",
        "    print('(10 minutes of training audio -> 20-30 minutes)')\n",
        "\n",
        "    audio_filepattern = os.path.join(audio_dir, '*')\n",
        "    audio_fp_str = f'\"{audio_filepattern}\"'\n",
        "    tfrecord_path_str = f'\"{data_dir}/train.tfrecord\"'\n",
        "\n",
        "    !ddsp_prepare_tfrecord \\\n",
        "    --input_audio_filepatterns=$audio_fp_str \\\n",
        "    --output_tfrecord_path=$tfrecord_path_str \\\n",
        "    --num_shards=10 \\\n",
        "    --sample_rate=$sample_rate \\\n",
        "    --frame_rate=$frame_rate \\\n",
        "    --example_secs=$example_secs \\\n",
        "    --hop_secs=$hop_secs \\\n",
        "    --viterbi=$viterbi \\\n",
        "    --center=$center &> /dev/null\n",
        "\n",
        "\n",
        "def train(model_dir, data_dir, steps=30000, save_steps=300):\n",
        "  file_pattern = os.path.join(data_dir, 'train.tfrecord*')\n",
        "  fp_str = f\"TFRecordProvider.file_pattern='{file_pattern}'\"\n",
        "\n",
        "  print(\"-------\", file_pattern, \"-------\")\n",
        "\n",
        "  # --- CUSTOM ---\n",
        "  if Threshold:\n",
        "    # Create a for loop and increase Training_Steps each time\n",
        "    for i in range(steps // Threshold):\n",
        "      current_num_steps = (i+1) * Threshold\n",
        "\n",
        "      print(\"\\n ---Current steps limit:\", current_num_steps, \"---\\n\")\n",
        "\n",
        "      if Threshold_Start <= current_num_steps:\n",
        "        !ddsp_run \\\n",
        "          --mode=train \\\n",
        "          --save_dir=\"$model_dir\" \\\n",
        "          --gin_file=models/vst/vst.gin \\\n",
        "          --gin_file=datasets/tfrecord.gin \\\n",
        "          --gin_param=\"$fp_str\" \\\n",
        "          --gin_param=\"TFRecordProvider.centered=True\" \\\n",
        "          --gin_param=\"TFRecordProvider.frame_rate=50\" \\\n",
        "          --gin_param=\"batch_size=16\" \\\n",
        "          --gin_param=\"train_util.train.num_steps=$current_num_steps\" \\\n",
        "          --gin_param=\"train_util.train.steps_per_save=$save_steps\" \\\n",
        "          --gin_param=\"trainers.Trainer.checkpoints_to_keep=3\"\n",
        "  # --- CUSTOM ---\n",
        "\n",
        "  !ddsp_run \\\n",
        "  --mode=train \\\n",
        "  --save_dir=\"$model_dir\" \\\n",
        "  --gin_file=models/vst/vst.gin \\\n",
        "  --gin_file=datasets/tfrecord.gin \\\n",
        "  --gin_param=\"$fp_str\" \\\n",
        "  --gin_param=\"TFRecordProvider.centered=True\" \\\n",
        "  --gin_param=\"TFRecordProvider.frame_rate=50\" \\\n",
        "  --gin_param=\"batch_size=16\" \\\n",
        "  --gin_param=\"train_util.train.num_steps=$steps\" \\\n",
        "  --gin_param=\"train_util.train.steps_per_save=$save_steps\" \\\n",
        "  --gin_param=\"trainers.Trainer.checkpoints_to_keep=3\"\n",
        "\n",
        "\n",
        "def reset_state(data_dir, audio_dir, model_dir):\n",
        "  model_dir_str = f'\"{model_dir}\"'\n",
        "  if tf.io.gfile.exists(data_dir):\n",
        "    !rm -r $data_dir\n",
        "    !rm -r $audio_dir\n",
        "\n",
        "\n",
        "def make_dirs(data_dir, audio_dir, model_dir):\n",
        "  !mkdir -p $data_dir\n",
        "  !mkdir -p $audio_dir\n",
        "  !mkdir -p $model_dir\n",
        "\n",
        "\n",
        "def export_and_download(model_dir, model_name='mymodel'):\n",
        "  global export_path\n",
        "  export_path = os.path.join(model_dir, model_name)\n",
        "\n",
        "  model_dir_str=f'\"{model_dir}\"'\n",
        "  export_path_str=f'\"{export_path}\"'\n",
        "\n",
        "  !ddsp_export \\\n",
        "  --name=$model_name \\\n",
        "  --model_path=$model_dir_str \\\n",
        "  --save_dir=$export_path_str \\\n",
        "  --inference_model=vst_stateless_predict_controls \\\n",
        "  --tflite \\\n",
        "  --notfjs\n",
        "\n",
        "  # Zip the whole directory.\n",
        "  zip_fname = f'{model_name}.zip'\n",
        "  zip_fp = os.path.join(model_dir, zip_fname)\n",
        "  print(f'Export complete! Zipping {export_path} to {zip_fp}')\n",
        "  !cd $model_dir_str && zip -r $zip_fname ./$model_name\n",
        "\n",
        "  print(f'Zipping Complete! {zip_fname}')\n",
        "  print(f'You can also find your model at {export_path}')\n",
        "\n",
        "\n",
        "def get_model_dir(base_dir):\n",
        "  base_str = 'ddsp-training'\n",
        "  dirs = tf.io.gfile.glob(os.path.join(base_dir, f'{base_str}-*'))\n",
        "  if dirs and not Ignore_Previous:\n",
        "    model_dir = dirs[-1]  # Sorted, so last is most recent.\n",
        "  else:\n",
        "    now = datetime.datetime.now().strftime('%Y-%m-%d-%H%M')\n",
        "    model_dir = os.path.join(base_dir, f'{base_str}-{now}')\n",
        "  return model_dir\n",
        "\n",
        "\n",
        "def get_gpu_type():\n",
        "    gpu_info = []\n",
        "    try:\n",
        "        bash_command = \"nvidia-smi --query-gpu=name --format=csv\"\n",
        "        output = subprocess.getoutput(bash_command)\n",
        "        lines = output.split(\"\\n\")\n",
        "        lines.pop(0)\n",
        "        return lines[0]\n",
        "    except (OSError, IndexError) as e:\n",
        "        print(\"GPU device is not available\")\n",
        "        return ''\n",
        "\n",
        "\n",
        "def gpu_check():\n",
        "  gpu_type = get_gpu_type()\n",
        "  print(f'Using a {gpu_type} GPU...')\n",
        "  print(\"Tensorflow Version:\", tf.__version__)\n",
        "  print(\"Tensorflow all GPUs:\", tf.config.list_physical_devices('GPU'))\n",
        "  print(\"Tensorflow GPU:\", tf.test.gpu_device_name())\n",
        "  print()\n",
        "\n",
        "\n",
        "def get_cloud_service_type(cloud_service_string=''):\n",
        "  cloud_service_type = CLOUD_NONE\n",
        "  if \"cloud\" in cloud_service_string.lower():\n",
        "    cloud_service_type = CLOUD_NEXTCLOUD\n",
        "    print(\"Using TUB-Cloud / Nextcloud\")\n",
        "\n",
        "  elif \"google\" in cloud_service_string.lower():\n",
        "    cloud_service_type = CLOUD_GDRIVE\n",
        "    print(\"Using Google Drive\")\n",
        "\n",
        "  else:\n",
        "    print('Skipping Cloud Setup...')\n",
        "    print('Upload Audio Manually...')\n",
        "\n",
        "  return cloud_service_type\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# Run\n",
        "# ------------------------------------------------------------------------------\n",
        "def run(cloud_service='', cloud_link='', base_directory=''):\n",
        "  cloud_service_type = get_cloud_service_type(cloud_service)\n",
        "\n",
        "  # Save data locally, but model on drive.\n",
        "  data_dir = os.path.join(base_directory, 'data')\n",
        "  audio_dir = os.path.join(base_directory, 'audio')\n",
        "  model_dir = get_model_dir(base_directory)\n",
        "\n",
        "  run_training(cloud_service_type=cloud_service_type, cloud_link=cloud_link,\n",
        "               data_dir=data_dir, audio_dir=audio_dir, model_dir=model_dir)\n",
        "\n",
        "\n",
        "def run_training(cloud_service_type=0, cloud_link='',\n",
        "                 data_dir='data', audio_dir='audio', model_dir = 'my_model'):\n",
        "  # ------------------------------------------------------------------------------\n",
        "  # Setup\n",
        "  # ------------------------------------------------------------------------------\n",
        "\n",
        "  if Ignore_Previous:\n",
        "    reset_state(data_dir, audio_dir, model_dir)\n",
        "  make_dirs(data_dir, audio_dir, model_dir)\n",
        "\n",
        "  # ------------------------------------------------------------------------------\n",
        "  # Dataset\n",
        "  # ------------------------------------------------------------------------------\n",
        "  tick = time.time()\n",
        "\n",
        "  get_audio_files(cloud_service_type, cloud_link, audio_dir)\n",
        "  prepare_dataset(audio_dir, data_dir)\n",
        "\n",
        "\n",
        "  # ------------------------------------------------------------------------------\n",
        "  # Train\n",
        "  # ------------------------------------------------------------------------------\n",
        "  tick = time.time()\n",
        "\n",
        "  print()\n",
        "  print('Training...')\n",
        "  train(model_dir, data_dir, steps=Training_Steps, save_steps=Steps_Per_Save)\n",
        "\n",
        "\n",
        "  # ------------------------------------------------------------------------------\n",
        "  # Export\n",
        "  # ------------------------------------------------------------------------------\n",
        "  tick = time.time()\n",
        "\n",
        "  print()\n",
        "  print('Exporting model...')\n",
        "  export_and_download(model_dir=model_dir, model_name=Name)\n",
        "\n",
        "  if Disconnect_Finished:\n",
        "    print(\"Dosconnecting from runtime...\")\n",
        "    runtime.unassign()\n",
        "\n",
        "\n",
        "# The single command.\n",
        "if Run_Training:\n",
        "  run(Cloud_Service, Dataset_Link)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Batch training\n",
        "#@markdown # Batch training\n",
        "\n",
        "#@markdown Training of several models in one go over multiple directories/zip-files.\n",
        "#@markdown Save each result in a seperate directory. <br>\n",
        "#@markdown Model name will be assumed to be the dir/zip name.\n",
        "\n",
        "#@markdown Instructions:\n",
        "#@markdown * Start the cell above (\"DDSP-VST Model Training\"), with **Run_Training** set to **false**\n",
        "#@markdown * Provide a link to a dataset below and choose the corresponding cloud service type\n",
        "#@markdown * Start ‚ñ∂Ô∏è the batch training in the upper left\n",
        "\n",
        "#@markdown _Note: The link should contain several directories and/or zip-files._\n",
        "\n",
        "#@markdown <br/>  Link to a Cloud dataset. The link should be public.\n",
        "Dataset_Link = 'https://tubcloud.tu-berlin.de/s/ye24sGnmtnnN75C'  #@param {type:\"string\"}\n",
        "\n",
        "#@markdown <br/> Cloud service type.\n",
        "Cloud_Service = \"TUB-Cloud/Nextcloud\" #@param [\"TUB-Cloud/Nextcloud\"]\n",
        "\n",
        "# Overwrite global variables\n",
        "Disconnect_Finished = False\n",
        "Cloud_File_Name = ''\n",
        "Ignore_Previous = False  # Would remove the copied audio files\n",
        "\n",
        "import owncloud\n",
        "import os\n",
        "\n",
        "\n",
        "def move_audio_files(src, dst):\n",
        "  \"\"\"\n",
        "  Moves audio files from src to dst, renaming them to ensure they don't have the same filenames.\n",
        "  No subdirectories will be created.\n",
        "  \"\"\"\n",
        "  mp3_files = glob.glob(os.path.join(src, '**', '*.mp3'), recursive=True)\n",
        "  wav_files = glob.glob(os.path.join(src, '**', '*.wav'), recursive=True)\n",
        "  audio_paths = mp3_files + wav_files\n",
        "  for audio_file in audio_paths:\n",
        "    base_name, ext = os.path.splitext(os.path.basename(audio_file))\n",
        "    base_name = base_name.replace(' ', '_')\n",
        "    destination = os.path.join(dst, f\"{base_name}_1{ext}\")\n",
        "\n",
        "    # Ensure the destination file name is unique\n",
        "    counter = 1\n",
        "    while os.path.exists(destination):\n",
        "      counter += 1\n",
        "      destination = os.path.join(dst, f\"{base_name}_{counter}{ext}\")\n",
        "\n",
        "    !mv -f \"$audio_file\" \"$destination\"\n",
        "\n",
        "\n",
        "def run_multiple(cloud_service='', cloud_link='', base_directory='models'):\n",
        "  # Download content to 'download'\n",
        "  download_dir = 'download'\n",
        "  audio_dir = 'audio'\n",
        "  !mkdir -p $download_dir\n",
        "\n",
        "  audio_zip_list = []\n",
        "\n",
        "  oc = owncloud.Client.from_public_link(cloud_link)\n",
        "  for content_element in oc.list(path=''):\n",
        "    filename = content_element.get_name()\n",
        "    local_download_file = (os.path.join(download_dir, filename) + '.zip').replace(' ', '_')\n",
        "\n",
        "    if content_element.is_dir():\n",
        "      # get_directory_as_zip OUTDATED!\n",
        "      # result = oc.get_directory_as_zip(remote_path=content_element.path, local_file=local_download_file[:-4])\n",
        "      zip_download_link = '\"' + cloud_link + '/download?files=' + filename.replace(' ', '%20') + '\"'\n",
        "      !wget $zip_download_link \\\n",
        "         --no-check-certificate --no-proxy --content-disposition \\\n",
        "         -O $local_download_file\n",
        "\n",
        "    elif filename.lower().endswith('.zip'):\n",
        "      local_download_file = local_download_file[:-4]\n",
        "      oc.get_file(remote_path=filename, local_file=local_download_file)\n",
        "\n",
        "    audio_zip_list.append(local_download_file)\n",
        "\n",
        "  print(f\"Running training for {len(audio_zip_list)} models...\")\n",
        "  tmp_dir = 'tmp'\n",
        "\n",
        "  # Create a sperate directory for each content of 'download'\n",
        "  for i, audio_zip in enumerate(audio_zip_list):\n",
        "    print(\"---------- Model\", i+1, \"----------\")\n",
        "    dirmodelname = os.path.join(base_directory, os.path.basename(audio_zip)[:-4])\n",
        "    dirmodelaudio = os.path.join(dirmodelname, audio_dir)\n",
        "    print(dirmodelaudio)\n",
        "\n",
        "    # Empty model audio directory\n",
        "    !rm -r $dirmodelaudio\n",
        "\n",
        "    # Create necessary directories\n",
        "    !mkdir -p $dirmodelname\n",
        "    !mkdir -p $dirmodelaudio\n",
        "    !mkdir -p $tmp_dir\n",
        "\n",
        "    # Unzip to tmp\n",
        "    !unzip -o -d $tmp_dir $audio_zip\n",
        "\n",
        "    # Move .wav and .mp3 files to 'audio'\n",
        "    #!find $tmp_dir -type f \\( -iname \\*.wav -o -iname \\*.mp3 \\) -exec sh -c 'cp \"{}\" \"$dirmodelaudio/$(basename \"{}\" | sed \"s/\\.[^.]*$//;s/$/_1.wav/\")\"' \\;\n",
        "    #!find $tmp_dir -type f \\( -iname \\*.wav -o -iname \\*.mp3 \\) -exec sh -c 'cp \"{}\" \"$dirmodelaudio/$(basename \"{}\" | sed \"s/\\.[^.]*$//;s/$/_1.wav/\")\"' \\;\n",
        "    move_audio_files(tmp_dir, dirmodelaudio)\n",
        "\n",
        "    # Remove the tmp directory for later models\n",
        "    !rm -r $tmp_dir\n",
        "\n",
        "    # Set the name of the model (name of the model directory)\n",
        "    global Name\n",
        "    Name = os.path.basename(dirmodelname)\n",
        "\n",
        "    # Run training and set 'base_directory' every time\n",
        "    run(cloud_service='', cloud_link='', base_directory=dirmodelname)\n",
        "\n",
        "\n",
        "run_multiple(cloud_service=Cloud_Service, cloud_link=Dataset_Link)"
      ],
      "metadata": {
        "id": "9hqbdZHkMPTW",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title  Loss visualizaion\n",
        "#@markdown #  Loss visualizaion\n",
        "#@markdown Run this code after the training is finished to visualize the loss over time. </br>\n",
        "#@markdown If a batch training was used, just the last result will be displayed.\n",
        "%load_ext tensorboard\n",
        "#%reload_ext tensorboard\n",
        "\n",
        "#@markdown <br>Leave empty to use summaries location from the last training above.\n",
        "Summaries_Location = '/content/ddsp-training-2024-01-16-1530/summaries/train' #@param {type:\"string\"}\n",
        "#export_path = '/content/gdrive/MyDrive/AnVoGen/Cat/ddsp-training-2024-01-10-1302/cat'\n",
        "\n",
        "logs = Summaries_Location\n",
        "if Summaries_Location is '':\n",
        "  MODEL_DIR = os.path.dirname(export_path)\n",
        "  logs = os.path.join(MODEL_DIR, 'summaries')\n",
        "\n",
        "print(\"Loading logs from:\", logs)\n",
        "\n",
        "%tensorboard --logdir $logs"
      ],
      "metadata": {
        "id": "Jb3iHjSc-1gk",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}